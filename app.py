
# DERS NOTU ANALÄ°Z ASÄ°STANI - CLOUD 


import os
import streamlit as st
from dotenv import load_dotenv
from groq import Groq
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer

# Ã‡evre deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# API AyarlarÄ±
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

# Sayfa AyarlarÄ±
st.set_page_config(
    page_title="ğŸ“ Ders Notu AsistanÄ±",
    page_icon="ğŸ“š",
    layout="wide"
)

st.title("ğŸ“ Ders Notu Analiz AsistanÄ± - Cloud")
st.markdown("---")

# EMBEDDING MODEL


@st.cache_resource
def load_embedding_model():
    """Embedding modelini yÃ¼kle (sadece bir kez)"""
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

embedding_model = load_embedding_model()


# SÄ°STEM BAÅLATMA


@st.cache_resource
def initialize_clients():
    """API istemcilerini baÅŸlat"""
    
    with st.spinner("ğŸ”§ Sistem baÅŸlatÄ±lÄ±yor..."):
        
        # Groq Client
        st.info("ğŸ¤– Groq AI baÄŸlantÄ±sÄ± kuruluyor...")
        try:
            groq_client = Groq(api_key=GROQ_API_KEY)
            st.success("âœ… Groq hazÄ±r!")
        except Exception as e:
            st.error(f"âŒ Groq hatasÄ±: {e}")
            st.stop()
        
        # Qdrant Client
        st.info("ğŸ“Š Qdrant veritabanÄ±na baÄŸlanÄ±lÄ±yor...")
        try:
            qdrant_client = QdrantClient(
                url=QDRANT_URL,
                api_key=QDRANT_API_KEY,
            )
            
            # Collection oluÅŸtur (yoksa)
            collection_name = "ders_notlari"
            collections = qdrant_client.get_collections().collections
            collection_exists = any(c.name == collection_name for c in collections)
            
            if not collection_exists:
                qdrant_client.create_collection(
                    collection_name=collection_name,
                    vectors_config=VectorParams(size=384, distance=Distance.COSINE)
                )
            
            st.success("âœ… Qdrant hazÄ±r!")
            return groq_client, qdrant_client, collection_name
            
        except Exception as e:
            st.error(f"âŒ Qdrant hatasÄ±: {e}")
            st.stop()

# Ä°stemcileri baÅŸlat
groq_client, qdrant_client, collection_name = initialize_clients()

st.markdown("---")

# YARDIMCI FONKSÄ°YONLAR


def create_embedding(text):
    """GerÃ§ek embedding oluÅŸtur (sentence-transformers ile)"""
    return embedding_model.encode(text).tolist()

def search_knowledge(query_text, limit=5):
    """Bilgi tabanÄ±nda arama yap"""
    try:
        query_vector = create_embedding(query_text)
        
        results = qdrant_client.query_points(
            collection_name=collection_name,
            query=query_vector,
            limit=limit
        )
        
        contexts = []
        if hasattr(results, 'points'):
            for point in results.points:
                if hasattr(point, 'payload') and 'text' in point.payload:
                    contexts.append(point.payload['text'])
        
        return contexts
    except Exception as e:
        st.error(f"Arama hatasÄ±: {e}")
        return []

def ask_groq(question, contexts):
    """Groq AI'dan cevap al"""
    
    # Context'leri birleÅŸtir
    if contexts and len(contexts) > 0:
        context_text = "\n\n".join(contexts)
    else:
        return "âŒ Ders notlarÄ±nda bu konuyla ilgili bilgi bulunamadÄ±. LÃ¼tfen Ã¶nce PDF yÃ¼kleyin."
    
    # Prompt oluÅŸtur
    prompt = f"""Sen bir ders notu asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki ders notlarÄ±na SADECE dayanarak soruyu cevapla.

DERS NOTLARI:
{context_text}

SORU: {question}

Ã–NEMLÄ°: Sadece yukarÄ±daki notlarda yazan bilgileri kullan. EÄŸer cevap notlarda yoksa "Bu bilgi notlarda bulunmuyor" de.

CEVAP (TÃ¼rkÃ§e):"""
    
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {
                    "role": "system",
                    "content": "Sen yardÄ±mcÄ± bir ders notu asistanÄ±sÄ±n. SADECE verilen notlara dayanarak TÃ¼rkÃ§e cevap veriyorsun. Notlarda olmayan bilgileri uydurma."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.5,
            max_tokens=1500,
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"âŒ Groq hatasÄ±: {str(e)}"

# PDF YÃœKLEME (Admin Panel)


with st.sidebar:
    st.header("ğŸ“¤ Ders Notu YÃ¼kle")
    
    uploaded_file = st.file_uploader("PDF yÃ¼kle", type=['pdf'])
    
    if uploaded_file and st.button("YÃ¼kle ve Analiz Et"):
        with st.spinner("PDF iÅŸleniyor..."):
            try:
                # PDF'i oku
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(uploaded_file)
                
                text_chunks = []
                for page_num, page in enumerate(pdf_reader.pages):
                    text = page.extract_text()
                    if text.strip():
                        # Metin parÃ§alarÄ±na bÃ¶l (800 karakter, daha iyi sonuÃ§lar iÃ§in)
                        chunks = [text[i:i+800] for i in range(0, len(text), 600)]
                        text_chunks.extend(chunks)
                
                # Ä°lerleme gÃ¶ster
                progress_bar = st.progress(0)
                
                # Qdrant'a kaydet
                batch_size = 10
                for i in range(0, len(text_chunks), batch_size):
                    batch = text_chunks[i:i+batch_size]
                    points = []
                    
                    for idx, chunk in enumerate(batch):
                        vector = create_embedding(chunk)
                        point = PointStruct(
                            id=hash(chunk + str(i + idx)) % (10 ** 8),
                            vector=vector,
                            payload={"text": chunk, "source": uploaded_file.name}
                        )
                        points.append(point)
                    
                    qdrant_client.upsert(
                        collection_name=collection_name,
                        points=points
                    )
                    
                    # Ä°lerleme gÃ¼ncelle
                    progress = min((i + batch_size) / len(text_chunks), 1.0)
                    progress_bar.progress(progress)
                
                st.success(f"âœ… {len(text_chunks)} metin parÃ§asÄ± baÅŸarÄ±yla yÃ¼klendi!")
                st.balloons()  # ğŸˆ BALON Ã‡IKIYOR!
                
            except Exception as e:
                st.error(f"âŒ YÃ¼kleme hatasÄ±: {e}")
    
    st.markdown("---")
    st.info("ğŸ’¡ Ä°lk kullanÄ±mda en az bir PDF yÃ¼klemelisiniz")
    
    # VeritabanÄ± durumu - METIN SAYISI
    try:
        count = qdrant_client.count(collection_name=collection_name)
        st.metric("ğŸ“Š YÃ¼klÃ¼ Metin SayÄ±sÄ±", count.count)  # ğŸ“Š METIN SAYISI BURADA!
    except:
        st.metric("ğŸ“Š YÃ¼klÃ¼ Metin SayÄ±sÄ±", 0)

# CHAT ARAYÃœZÃœ


st.markdown("### ğŸ’¬ AsistanÄ±nÄ±za Soru Sorun")

# Chat geÃ§miÅŸi
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ã–nceki mesajlarÄ± gÃ¶ster
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# KullanÄ±cÄ± inputu
if prompt := st.chat_input("Sorunuzu yazÄ±n... (Ã¶rn: 'Python'da dÃ¶ngÃ¼ nedir?')"):
    
    # KullanÄ±cÄ± mesajÄ±
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Asistan cevabÄ±
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Notlarda arÄ±yorum..."):
            
            # Bilgi tabanÄ±nda ara
            contexts = search_knowledge(prompt, limit=5)
            
            # Debug bilgisi (geliÅŸtirme iÃ§in)
            if len(contexts) > 0:
                with st.expander("ğŸ“š Bulunan kaynak sayÄ±sÄ±"):
                    st.write(f"{len(contexts)} adet ilgili metin parÃ§asÄ± bulundu")
            
            # Groq'tan cevap al
            answer = ask_groq(prompt, contexts)
            
            st.markdown(answer)
            
            # Kaydet
            st.session_state.messages.append({
                "role": "assistant", 
                "content": answer
            })

# YAN PANEL - BÄ°LGÄ°

with st.sidebar:
    st.markdown("---")
    st.header("ğŸ“– KullanÄ±m KÄ±lavuzu")
    
    st.markdown("""
    **NasÄ±l KullanÄ±lÄ±r:**
    1. YukarÄ±dan PDF yÃ¼kleyin
    2. Alt kÄ±sÄ±mda soru sorun
    3. AI notlardan bilgi bulup cevaplar
    
    **Ã–rnek Sorular:**
    - "Bu derste hangi konular var?"
    - "Python'da dÃ¶ngÃ¼ nedir?"
    - "Fonksiyon Ã¶rnekleri ver"
    - "CSS nedir"
    """)
    
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
        st.session_state.messages = []
        st.rerun()

